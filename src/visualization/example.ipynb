{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabM\n",
    "\n",
    "This is a standalone usage example for the TabM project.\n",
    "The easiest way to run it is [Pixi](https://pixi.sh/latest/#installation):\n",
    "\n",
    "```shell\n",
    "git clone https://github.com/yandex-research/tabm\n",
    "cd tabm\n",
    "\n",
    "# With GPU:\n",
    "pixi run -e cuda jupyter-lab example.ipynb\n",
    "\n",
    "# Without GPU:\n",
    "pixi run jupyter-lab example.ipynb\n",
    "```\n",
    "\n",
    "For the full overview of the project, and for non-Pixi environment setups, see README in the repository:\n",
    "https://github.com/yandex-research/tabm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E402\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from typing import Literal, NamedTuple\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import rtdl_num_embeddings  # https://github.com/yandex-research/rtdl-num-embeddings\n",
    "import scipy.special\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch import Tensor\n",
    "from tqdm.std import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "from tabm_reference import Model, make_parameter_groups\n",
    "\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed + 1)\n",
    "torch.manual_seed(seed + 2)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_TO_NUM_LABELS = {\n",
    "    \"Normal traffic\": 0,\n",
    "    \"Suspicious traffic\": 1,\n",
    "    \"DDoS attack\": 2,\n",
    "}\n",
    "\n",
    "component_columns = [\n",
    "    \"Attack ID\", \"Detect count\", \"Card\", \"Victim IP\", \"Port number\",\n",
    "    \"Attack code\", \"Significant flag\", \"Packet speed\", \"Data speed\", \"Avg packet len\",\n",
    "    \"Source IP count\", \"Time\"\n",
    "]\n",
    "\n",
    "event_columns = [\n",
    "    \"Attack ID\", \"Card\", \"Victim IP\", \"Port number\", \"Attack code\", \n",
    "    \"Detect count\", \"Significant flag\", \"Packet speed\", \"Data speed\", \n",
    "    \"Avg packet len\", \"Avg source IP count\", \"Start time\", \"End time\", \n",
    "    \"Whitelist flag\", \"Type\"\n",
    "]\n",
    "\n",
    "class DDoSDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.train_data_paths = [f'/home/appuser/data/train/SCLDDoS2024_SetA_events_extended.csv',\n",
    "                                 f'/home/appuser/data/train/SCLDDoS2024_SetB_events_extended.csv']\n",
    "        self.test_data_paths = [f'/home/appuser/data/test/SCLDDoS2024_SetC_events_extended.csv']     \n",
    "        \n",
    "        self.split = split   \n",
    "        \n",
    "        if split == 'train':\n",
    "            self.features, self.lables = self.load_data(self.train_data_paths, apply_smote=False)\n",
    "        elif split == 'test':\n",
    "            self.features, self.lables = self.load_data(self.test_data_paths, apply_smote=False)\n",
    "        else:\n",
    "            print(\"Invalid split. Use 'train' or 'test'\")\n",
    "            \n",
    "    \n",
    "    def get_ports(self):\n",
    "        return self.ddos_ports\n",
    "    \n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.features.numpy(), self.lables.numpy()\n",
    "    \n",
    "    def engineer_features_from_components(self, df_components):\n",
    "\n",
    "        grouped = df_components.groupby('Attack ID')\n",
    "\n",
    "        features = pd.DataFrame()\n",
    "\n",
    "        features['Unique Ports'] = grouped['Port number'].nunique()\n",
    "        features['Unique Victim IPs'] = grouped['Victim IP'].nunique()\n",
    "\n",
    "        return features.reset_index()\n",
    "    \n",
    "    # ChatGPT-version\n",
    "    def add_protocol_columns(self, df):\n",
    "        # DNS: Port 53\n",
    "        df['DNS'] = df['Port number'].apply(lambda x: 1 if x == 53 else 0)\n",
    "        \n",
    "        # RDP: Port 3389\n",
    "        df['RDP'] = df['Port number'].apply(lambda x: 1 if x == 3389 else 0)\n",
    "        \n",
    "        # TCP: Ports 80, 443, 21, 22\n",
    "        df['TCP'] = df['Port number'].apply(lambda x: 1 if x in [80, 443, 21, 22, 8080, 8001] else 0)\n",
    "        \n",
    "        # SYN: Ports 80, 443\n",
    "        df['SYN'] = df['Port number'].apply(lambda x: 1 if x in [80, 443] else 0)\n",
    "        \n",
    "        # UDP: Ports 53, 123, 161, 162, 69\n",
    "        df['UDP'] = df['Port number'].apply(lambda x: 1 if x in [53, 123, 161, 162, 69, 123] else 0)\n",
    "        \n",
    "        # CoAP: Port 5683\n",
    "        df['CoAP'] = df['Port number'].apply(lambda x: 1 if x == 5683 else 0)\n",
    "\n",
    "        # Additional ports that frequently appear in DDoS attacks\n",
    "        df['Attack Ports'] = df['Port number'].apply(lambda x: 1 if x in [51822, 7777, 1900, 9987, 8080, 7547, 7010, 7007, 2301] else 0)\n",
    "\n",
    "        return df\n",
    "        \n",
    "    # def add_protocol_columns(self, df):\n",
    "    #     ''' UDP-based protocols '''\n",
    "    #     # DNS: Port 53\n",
    "    #     df['DNS'] = df['Port number'].apply(lambda x: 1 if x in [53, 5353] else 0)\n",
    "        \n",
    "    #     # NTP: Port 123\n",
    "    #     df['NTP'] = df['Port number'].apply(lambda x: 1 if x == 123 else 0)\n",
    "        \n",
    "    #     # SNMP: Ports 161, 162\n",
    "    #     df['SNMP'] = df['Port number'].apply(lambda x: 1 if x in [161, 162] else 0)\n",
    "        \n",
    "    #     # SSDP: Port 1900\n",
    "    #     df['SSDP'] = df['Port number'].apply(lambda x: 1 if x == 1900 else 0)\n",
    "        \n",
    "    #     # CLDAP: Port 389\n",
    "    #     df['CLDAP'] = df['Port number'].apply(lambda x: 1 if x == 389 else 0)\n",
    "        \n",
    "    #     # Quic: Port 443\n",
    "    #     df['QUIC'] = df['Port number'].apply(lambda x: 1 if x == 443 else 0)\n",
    "        \n",
    "    #     # RDP: Port 3389\n",
    "    #     df['RDP'] = df['Port number'].apply(lambda x: 1 if x == 3389 else 0)\n",
    "        \n",
    "    #     # CoAP: Port 5683, 5684\n",
    "    #     df['CoAP'] = df['Port number'].apply(lambda x: 1 if x in [5683, 5684] else 0)\n",
    "        \n",
    "    #     # TCP: Ports 80, 443, 21, 22\n",
    "    #     df['HTTP Flood'] = df['Port number'].apply(lambda x: 1 if x in [80, 443] else 0)\n",
    "                \n",
    "    #     # FTP: Port 21\n",
    "    #     df['FTP'] = df['Port number'].apply(lambda x: 1 if x == 21 else 0)\n",
    "        \n",
    "    #     # SSH: Port 22\n",
    "    #     df['SSH'] = df['Port number'].apply(lambda x: 1 if x == 22 else 0)\n",
    "    \n",
    "    #     df['Memcached'] = df['Port number'].apply(lambda x: 1 if x == 11211 else 0)\n",
    "        \n",
    "    #     df['WS-DD'] = df['Port number'].apply(lambda x: 1 if x == 3702 else 0)\n",
    "        \n",
    "    #     df['NetBIOS'] = df['Port number'].apply(lambda x: 1 if x in [137, 138] else 0)\n",
    "        \n",
    "    #     df['Kubernetes'] = df['Port number'].apply(lambda x: 1 if x in [10250, 6443] else 0)\n",
    "\n",
    "    #     return df\n",
    "        \n",
    "    # preload the data as it makes the training much faster (and it easily fits in memory)\n",
    "    def load_data(self, data_paths, apply_smote=False, undersample=False, sample_factor=4, add_features=True):\n",
    "        data = []\n",
    "        component_data = []\n",
    "        \n",
    "        for path in data_paths:\n",
    "            event_df = pd.read_csv(path).fillna(0)\n",
    "            data.append(event_df)\n",
    "\n",
    "            # Attempt to load corresponding component file\n",
    "            comp_path = path.replace('_events_extended.csv', '_components.csv')\n",
    "            ref_event_path = path.replace('_events_extended.csv', '_events.csv')\n",
    "            if os.path.exists(comp_path) and add_features:\n",
    "                # Load event data\n",
    "                ref_ev_df = pd.read_csv(ref_event_path).fillna(0)\n",
    "                ref_ev_df.columns = event_columns\n",
    "\n",
    "                # Filter out invalid 'Attack ID's based on 'End time'\n",
    "                ref_ev_df2 = ref_ev_df[ref_ev_df['End time'].astype(str) != '0']\n",
    "                invalid_attack_ids = ref_ev_df[ref_ev_df['End time'].astype(str) == '0']['Attack ID'].unique()\n",
    "\n",
    "                # Filter the event data by removing rows with invalid 'Attack ID's\n",
    "                valid_attack_ids = ref_ev_df2['Attack ID'].unique()  # Attack IDs present in valid events\n",
    "\n",
    "                # Load component data\n",
    "                component_df = pd.read_csv(comp_path).fillna(0)\n",
    "                component_df.columns = component_columns\n",
    "\n",
    "                # Remove invalid attack IDs from component data\n",
    "                component_df = component_df[~component_df['Attack ID'].isin(invalid_attack_ids)]\n",
    "                \n",
    "                # Now filter component data to only include 'Attack ID's present in valid events\n",
    "                component_df = component_df[component_df['Attack ID'].isin(valid_attack_ids)]\n",
    "\n",
    "                # Append the filtered component data\n",
    "                component_data.append(component_df)\n",
    "            else:\n",
    "                print(f\"Component file not found: {comp_path}\")\n",
    "        \n",
    "        df = pd.concat(data, ignore_index=True)\n",
    "        \n",
    "        if component_data:\n",
    "            df_components = pd.concat(component_data, ignore_index=True)\n",
    "            comp_features = self.engineer_features_from_components(df_components)\n",
    "            df = pd.concat([df, comp_features], axis=1)\n",
    "            df = df.drop(columns=['Attack ID'])\n",
    "            cols = list(df.columns)\n",
    "            cols[-3], cols[-1] = cols[-1], cols[-3]\n",
    "            df = df[cols]\n",
    "            df = df.dropna(how='all')\n",
    "            \n",
    "        \n",
    "        self.ddos_ports = df[df['Type'] == \"DDoS attack\"][\"Port number\"].unique()\n",
    "        \n",
    "        #feature_columns = df.columns[:19]  # All except the last column\n",
    "        \n",
    "        df = df.loc[:, ~df.columns.str.contains('Ac')]\n",
    "        feature_columns = df.columns[:-1]\n",
    "        label_column = df.columns[-1]  # The last column\n",
    "        \n",
    "        # Convert categorical labels to numeric using the dictionary\n",
    "        df[label_column] = df[label_column].map(CAT_TO_NUM_LABELS)\n",
    "        \n",
    "        # Check for missing or unknown labels\n",
    "        if df[label_column].isna().any():\n",
    "            print(df[label_column].isna().sum(), \"missing labels\")\n",
    "\n",
    "        X = df[feature_columns]\n",
    "        if (add_features):\n",
    "            X = self.add_protocol_columns(X)\n",
    "        y = df[label_column]\n",
    "        \n",
    "        self.columns = X.columns\n",
    "        \n",
    "        \n",
    "        # Normalize the features\n",
    "        #features = self.normalize(features)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        features = torch.tensor(X.values, dtype=torch.float32)\n",
    "        labels = torch.tensor(y.values, dtype=torch.long)  # Classification requires long dtype\n",
    "        \n",
    "        \n",
    "        \n",
    "        if undersample and self.split == 'train':\n",
    "            # Undersample the majority class (label=0)\n",
    "            class_0_indices = np.where(labels.cpu().numpy() == 0)[0]\n",
    "            class_1_indices = np.where(labels.cpu().numpy() == 1)[0]\n",
    "            class_2_indices = np.where(labels.cpu().numpy() == 2)[0]\n",
    "\n",
    "            # Randomly undersample the majority class\n",
    "            num_class_0_samples = sample_factor*(len(class_1_indices) + len(class_2_indices))  # Same number as the minority class\n",
    "            class_0_indices_undersampled = np.random.choice(class_0_indices, num_class_0_samples, replace=False)\n",
    "\n",
    "            # Concatenate indices of class 1, 2, and undersampled class 0\n",
    "            undersampled_indices = np.concatenate([class_0_indices_undersampled, class_1_indices, class_2_indices])\n",
    "\n",
    "            # Subset the dataset to include only the sampled indices\n",
    "            features = features[undersampled_indices]\n",
    "            labels = labels[undersampled_indices]\n",
    "\n",
    "        return features, labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.lables[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DDoSDataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Dataset.\n",
    "TaskType = Literal['regression', 'binclass', 'multiclass']\n",
    "\n",
    "# Regression.\n",
    "task_type: TaskType = 'multiclass'\n",
    "n_classes = None\n",
    "dataset = sklearn.datasets.fetch_california_housing()\n",
    "X_cont: np.ndarray = dataset['data']\n",
    "Y: np.ndarray = dataset['target']\n",
    "\n",
    "dataset = DDoSDataset(split='train')\n",
    "X_cont = dataset.features.numpy()\n",
    "Y = dataset.lables.numpy()\n",
    "\n",
    "\n",
    "# Classification.\n",
    "n_classes = 3\n",
    "assert n_classes >= 2\n",
    "task_type: TaskType = 'binclass' if n_classes == 2 else 'multiclass'\n",
    "# X_cont, Y = sklearn.datasets.make_classification(\n",
    "#     n_samples=20000,\n",
    "#     n_features=8,\n",
    "#     n_classes=n_classes,\n",
    "#     n_informative=3,\n",
    "#     n_redundant=2,\n",
    "# )\n",
    "\n",
    "#task_is_regression = task_type == 'regression'\n",
    "\n",
    "# >>> Continuous features.\n",
    "X_cont: np.ndarray = X_cont.astype(np.float32)\n",
    "n_cont_features = X_cont.shape[1]\n",
    "\n",
    "# # >>> Categorical features.\n",
    "# # NOTE: the above datasets do not have categorical features, however,\n",
    "# # for the demonstration purposes, it is possible to generate them.\n",
    "# cat_cardinalities = [\n",
    "#     # NOTE: uncomment the two lines below to add two categorical features.\n",
    "#     # 4,  # Allowed values: [0, 1, 2, 3].\n",
    "#     # 7,  # Allowed values: [0, 1, 2, 3, 4, 5, 6].\n",
    "# ]\n",
    "# X_cat = (\n",
    "#     np.column_stack(\n",
    "#         [np.random.randint(0, c, (len(X_cont),)) for c in cat_cardinalities]\n",
    "#     )\n",
    "#     if cat_cardinalities\n",
    "#     else None\n",
    "# )\n",
    "\n",
    "# >>> Labels.\n",
    "if task_type == 'regression':\n",
    "    Y = Y.astype(np.float32)\n",
    "else:\n",
    "    assert n_classes is not None\n",
    "    Y = Y.astype(np.int64)\n",
    "    assert set(Y.tolist()) == set(\n",
    "        range(n_classes)\n",
    "    ), 'Classification labels must form the range [0, 1, ..., n_classes - 1]'\n",
    "\n",
    "# >>> Split the dataset.\n",
    "all_idx = np.arange(len(Y))\n",
    "train_idx, val_idx = sklearn.model_selection.train_test_split(\n",
    "    all_idx, train_size=0.8\n",
    ")\n",
    "\n",
    "data_numpy = {\n",
    "    'train': {'x_cont': X_cont[train_idx], 'y': Y[train_idx]},\n",
    "    'val': {'x_cont': X_cont[val_idx], 'y': Y[val_idx]},\n",
    "}\n",
    "\n",
    "s = 0\n",
    "# if X_cat is not None:\n",
    "#     data_numpy['train']['x_cat'] = X_cat[train_idx]\n",
    "#     data_numpy['val']['x_cat'] = X_cat[val_idx]\n",
    "#     data_numpy['test']['x_cat'] = X_cat[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Dataset C as the testing class\n",
    "dataset = DDoSDataset(split='test')\n",
    "X_cont = dataset.features.numpy()\n",
    "Y = dataset.lables.numpy()\n",
    "\n",
    "\n",
    "# Classification.\n",
    "n_classes = 3\n",
    "assert n_classes >= 2\n",
    "task_type: TaskType = 'binclass' if n_classes == 2 else 'multiclass'\n",
    "# X_cont, Y = sklearn.datasets.make_classification(\n",
    "#     n_samples=20000,\n",
    "#     n_features=8,\n",
    "#     n_classes=n_classes,\n",
    "#     n_informative=3,\n",
    "#     n_redundant=2,\n",
    "# )\n",
    "\n",
    "#task_is_regression = task_type == 'regression'\n",
    "\n",
    "# >>> Continuous features.\n",
    "X_cont: np.ndarray = X_cont.astype(np.float32)\n",
    "n_cont_features = X_cont.shape[1]\n",
    "\n",
    "# >>> Labels.\n",
    "if task_type == 'regression':\n",
    "    Y = Y.astype(np.float32)\n",
    "else:\n",
    "    assert n_classes is not None\n",
    "    Y = Y.astype(np.int64)\n",
    "    assert set(Y.tolist()) == set(\n",
    "        range(n_classes)\n",
    "    ), 'Classification labels must form the range [0, 1, ..., n_classes - 1]'\n",
    "    \n",
    "    \n",
    "data_numpy['test'] = {'x_cont': X_cont, 'y': Y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature preprocessing.\n",
    "# NOTE\n",
    "# The choice between preprocessing strategies depends on a task and a model.\n",
    "\n",
    "# Simple preprocessing strategy.\n",
    "# preprocessing = sklearn.preprocessing.StandardScaler().fit(\n",
    "#     data_numpy['train']['x_cont']\n",
    "# )\n",
    "\n",
    "# Advanced preprocessing strategy.\n",
    "# The noise is added to improve the output of QuantileTransformer in some cases.\n",
    "\n",
    "# own\n",
    "port_columns = [\n",
    "    'DNS', 'NTP', 'SNMP', 'SSDP', 'CLDAP', 'QUIC', 'RDP', 'CoAP', \n",
    "    'HTTP Flood', 'FTP', 'SSH', 'Memcached', 'WS-DD', 'NetBIOS', 'Kubernetes'\n",
    "]\n",
    "\n",
    "# gpt\n",
    "port_columns = [\n",
    "    'DNS', 'RDP', 'TCP', 'SYN', 'UDP', 'CoAP', 'Attack Ports'\n",
    "]\n",
    "\n",
    "continuous_feature_indices = [i for i, col in enumerate(dataset.columns) \n",
    "                            if col not in port_columns and col != 'Port number']\n",
    "\n",
    "\n",
    "X_cont_train_numpy = data_numpy['train']['x_cont'][:, continuous_feature_indices]\n",
    "noise = (\n",
    "    np.random.default_rng(0)\n",
    "    .normal(0.0, 1e-5, X_cont_train_numpy.shape)\n",
    "    .astype(X_cont_train_numpy.dtype)\n",
    ")\n",
    "preprocessing = sklearn.preprocessing.QuantileTransformer(\n",
    "    n_quantiles=max(min(len(train_idx) // 30, 1000), 10),\n",
    "    output_distribution='normal',\n",
    "    subsample=10**9,\n",
    ").fit(X_cont_train_numpy + noise)\n",
    "del X_cont_train_numpy\n",
    "\n",
    "# Apply the preprocessing to the training, test and validation sets.\n",
    "for part in data_numpy:\n",
    "    # Transform only continuous features\n",
    "    data_numpy[part]['x_cont'][:, continuous_feature_indices] = preprocessing.transform(\n",
    "        data_numpy[part]['x_cont'][:, continuous_feature_indices]\n",
    "    )\n",
    "    # Leave port features unchanged\n",
    "\n",
    "# Label preprocessing.\n",
    "class RegressionLabelStats(NamedTuple):\n",
    "    mean: float\n",
    "    std: float\n",
    "\n",
    "\n",
    "Y_train = data_numpy['train']['y'].copy()\n",
    "if task_type == 'regression':\n",
    "    # For regression tasks, it is highly recommended to standardize the training labels.\n",
    "    regression_label_stats = RegressionLabelStats(\n",
    "        Y_train.mean().item(), Y_train.std().item()\n",
    "    )\n",
    "    Y_train = (Y_train - regression_label_stats.mean) / regression_label_stats.std\n",
    "else:\n",
    "    regression_label_stats = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PyTorch settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:        CUDA\n",
      "AMP:           False (dtype: torch.bfloat16)\n",
      "torch.compile: False\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convert data to tensors\n",
    "data = {\n",
    "    part: {k: torch.as_tensor(v, device=device) for k, v in data_numpy[part].items()}\n",
    "    for part in data_numpy\n",
    "}\n",
    "Y_train = torch.as_tensor(Y_train, device=device)\n",
    "if task_type == 'regression':\n",
    "    for part in data:\n",
    "        data[part]['y'] = data[part]['y'].float()\n",
    "    Y_train = Y_train.float()\n",
    "\n",
    "# Automatic mixed precision (AMP)\n",
    "# torch.float16 is implemented for completeness,\n",
    "# but it was not tested in the project,\n",
    "# so torch.bfloat16 is used by default.\n",
    "amp_dtype = (\n",
    "    torch.bfloat16\n",
    "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "    else torch.float16\n",
    "    if torch.cuda.is_available()\n",
    "    else None\n",
    ")\n",
    "# Changing False to True will result in faster training on compatible hardware.\n",
    "amp_enabled = False and amp_dtype is not None\n",
    "grad_scaler = torch.cuda.amp.GradScaler() if amp_dtype is torch.float16 else None  # type: ignore\n",
    "\n",
    "# torch.compile\n",
    "compile_model = False\n",
    "\n",
    "# fmt: off\n",
    "print(\n",
    "    f'Device:        {device.type.upper()}'\n",
    "    f'\\nAMP:           {amp_enabled} (dtype: {amp_dtype})'\n",
    "    f'\\ntorch.compile: {compile_model}'\n",
    ")\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one of the two configurations below.\n",
    "\n",
    "# TabM\n",
    "arch_type = 'tabm'\n",
    "bins = None\n",
    "\n",
    "# TabM-mini with the piecewise-linear embeddings.\n",
    "# arch_type = 'tabm-mini'\n",
    "# bins = rtdl_num_embeddings.compute_bins(data['train']['x_cont'])\n",
    "\n",
    "# arch_type = 'tabm-packed'\n",
    "# bins = rtdl_num_embeddings.compute_bins(data['train']['x_cont'])\n",
    "\n",
    "# d_block: 512\n",
    "# n_blocks: 3\n",
    "\n",
    "model = Model(\n",
    "    n_num_features=n_cont_features,\n",
    "    cat_cardinalities=[],\n",
    "    n_classes=n_classes,\n",
    "    backbone={\n",
    "        'type': 'MLP',\n",
    "        'n_blocks': 3 if bins is None else 2,\n",
    "        'd_block': 256,\n",
    "        'dropout': 0.2,\n",
    "        'n_blocks': 5\n",
    "    },\n",
    "    bins=bins,\n",
    "    num_embeddings=(\n",
    "        None\n",
    "        if bins is None\n",
    "        else {\n",
    "            'type': 'PiecewiseLinearEmbeddings',\n",
    "            'd_embedding': 32,\n",
    "            'activation': False,\n",
    "            'version': 'B',\n",
    "        }\n",
    "    ),\n",
    "    arch_type=arch_type,\n",
    "    k=48,\n",
    "    share_training_batches=True,\n",
    ").to(device)\n",
    "optimizer = torch.optim.AdamW(make_parameter_groups(model), lr=1e-3, weight_decay=3e-4)\n",
    "\n",
    "if compile_model:\n",
    "    # NOTE\n",
    "    # `torch.compile` is intentionally called without the `mode` argument\n",
    "    # (mode=\"reduce-overhead\" caused issues during training with torch==2.0.1).\n",
    "    model = torch.compile(model)\n",
    "    evaluation_mode = torch.no_grad\n",
    "else:\n",
    "    evaluation_mode = torch.inference_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score before training: 0.1826\n"
     ]
    }
   ],
   "source": [
    "@torch.autocast(device.type, enabled=amp_enabled, dtype=amp_dtype)  # type: ignore[code]\n",
    "def apply_model(part: str, idx: Tensor) -> Tensor:\n",
    "    return (\n",
    "        model(\n",
    "            data[part]['x_cont'][idx],\n",
    "            data[part]['x_cat'][idx] if 'x_cat' in data[part] else None,\n",
    "        )\n",
    "        .squeeze(-1)  # Remove the last dimension for regression tasks.\n",
    "        .float()\n",
    "    )\n",
    "\n",
    "\n",
    "base_loss_fn = F.mse_loss if task_type == 'regression' else F.cross_entropy\n",
    "weight = torch.tensor([1.0, 1.0, 3.0], device=device)\n",
    "#weight = torch.tensor([1.0, 1.0, 1.0], device=device)\n",
    "\n",
    "\n",
    "def loss_fn(y_pred: Tensor, y_true: Tensor) -> Tensor:\n",
    "    # TabM produces k predictions. Each of them must be trained separately.\n",
    "    # (regression)     y_pred.shape == (batch_size, k)\n",
    "    # (classification) y_pred.shape == (batch_size, k, n_classes)\n",
    "    k = y_pred.shape[-1 if task_type == 'regression' else -2]\n",
    "    return base_loss_fn(\n",
    "        y_pred.flatten(0, 1),\n",
    "        y_true.repeat_interleave(k) if model.share_training_batches else y_true,\n",
    "        weight=weight,\n",
    "    )\n",
    "\n",
    "\n",
    "@evaluation_mode()\n",
    "def evaluate(part: str) -> float:\n",
    "    model.eval()\n",
    "\n",
    "    # When using torch.compile, you may need to reduce the evaluation batch size.\n",
    "    eval_batch_size = 8096\n",
    "    y_pred: np.ndarray = (\n",
    "        torch.cat(\n",
    "            [\n",
    "                apply_model(part, idx)\n",
    "                for idx in torch.arange(len(data[part]['y']), device=device).split(\n",
    "                    eval_batch_size\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    if task_type == 'regression':\n",
    "        # Transform the predictions back to the original label space.\n",
    "        assert regression_label_stats is not None\n",
    "        y_pred = y_pred * regression_label_stats.std + regression_label_stats.mean\n",
    "\n",
    "    # Compute the mean of the k predictions.\n",
    "    if task_type != 'regression':\n",
    "        # For classification, the mean must be computed in the probabily space.\n",
    "        y_pred = scipy.special.softmax(y_pred, axis=-1)\n",
    "    y_pred = y_pred.mean(1)\n",
    "\n",
    "    y_true = data[part]['y'].cpu().numpy()\n",
    "    score = (\n",
    "        -(sklearn.metrics.mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "        if task_type == 'regression'\n",
    "        else sklearn.metrics.f1_score(y_true, y_pred.argmax(1), average='macro')\n",
    "    )\n",
    "    return float(score)  # The higher -- the better.\n",
    "\n",
    "\n",
    "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 828/828 [00:05<00:00, 138.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.3231 (test) 0.3280\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 828/828 [00:05<00:00, 139.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.3231 (test) 0.3280\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 828/828 [00:05<00:00, 139.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.4496 (test) 0.5801\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 828/828 [00:05<00:00, 139.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.5953 (test) 0.6678\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 828/828 [00:06<00:00, 137.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.5995 (test) 0.6726\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 828/828 [00:05<00:00, 138.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.5980 (test) 0.6643\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 828/828 [00:06<00:00, 137.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.6018 (test) 0.6814\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 828/828 [00:06<00:00, 136.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.5982 (test) 0.6826\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 828/828 [00:06<00:00, 136.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.6002 (test) 0.6740\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 828/828 [00:06<00:00, 136.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.6051 (test) 0.6809\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 828/828 [00:06<00:00, 136.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.6066 (test) 0.6792\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 828/828 [00:06<00:00, 136.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.6067 (test) 0.6792\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 828/828 [00:06<00:00, 137.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.6097 (test) 0.6813\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 828/828 [00:06<00:00, 137.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.6094 (test) 0.6809\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 828/828 [00:06<00:00, 136.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.6125 (test) 0.6959\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 828/828 [00:06<00:00, 135.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.6160 (test) 0.6951\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 828/828 [00:06<00:00, 137.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.6478 (test) 0.7095\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 828/828 [00:06<00:00, 137.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.6823 (test) 0.7265\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 828/828 [00:06<00:00, 136.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.7187 (test) 0.7338\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 828/828 [00:06<00:00, 135.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8167 (test) 0.6885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 828/828 [00:06<00:00, 135.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8223 (test) 0.7119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 828/828 [00:06<00:00, 136.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8260 (test) 0.6963\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 828/828 [00:06<00:00, 136.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8305 (test) 0.7377\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 828/828 [00:06<00:00, 135.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8349 (test) 0.7387\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 828/828 [00:06<00:00, 136.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8410 (test) 0.7963\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 828/828 [00:06<00:00, 135.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8378 (test) 0.7658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 828/828 [00:06<00:00, 135.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8364 (test) 0.7330\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 828/828 [00:06<00:00, 136.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8300 (test) 0.7761\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 828/828 [00:06<00:00, 136.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8371 (test) 0.7692\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 828/828 [00:06<00:00, 136.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8385 (test) 0.7875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 828/828 [00:06<00:00, 135.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8457 (test) 0.7610\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 828/828 [00:06<00:00, 136.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8455 (test) 0.7809\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 828/828 [00:06<00:00, 136.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8479 (test) 0.7747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 828/828 [00:06<00:00, 136.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8389 (test) 0.7795\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 828/828 [00:06<00:00, 136.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8485 (test) 0.8105\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 828/828 [00:06<00:00, 136.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8555 (test) 0.7968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 828/828 [00:06<00:00, 136.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8356 (test) 0.7873\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 828/828 [00:06<00:00, 135.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8437 (test) 0.7846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 828/828 [00:06<00:00, 136.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8511 (test) 0.7982\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 828/828 [00:06<00:00, 136.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8564 (test) 0.7915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 828/828 [00:06<00:00, 136.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8420 (test) 0.7879\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 828/828 [00:06<00:00, 136.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8477 (test) 0.8305\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 828/828 [00:06<00:00, 136.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8499 (test) 0.8070\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 828/828 [00:06<00:00, 136.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8495 (test) 0.7926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 828/828 [00:06<00:00, 136.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8438 (test) 0.8062\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 828/828 [00:06<00:00, 136.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8517 (test) 0.8153\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 828/828 [00:06<00:00, 136.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8539 (test) 0.7828\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 828/828 [00:06<00:00, 134.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8496 (test) 0.8256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 828/828 [00:06<00:00, 135.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8537 (test) 0.8298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 828/828 [00:06<00:00, 135.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8421 (test) 0.7973\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 828/828 [00:06<00:00, 135.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8542 (test) 0.8068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 828/828 [00:06<00:00, 136.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8612 (test) 0.8117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 828/828 [00:06<00:00, 135.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8568 (test) 0.8219\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 828/828 [00:06<00:00, 136.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8601 (test) 0.7949\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 828/828 [00:06<00:00, 135.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8479 (test) 0.8037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 828/828 [00:06<00:00, 135.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8562 (test) 0.8115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 828/828 [00:06<00:00, 136.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8611 (test) 0.8246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 828/828 [00:06<00:00, 136.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8586 (test) 0.8100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 828/828 [00:06<00:00, 136.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8591 (test) 0.8170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 828/828 [00:06<00:00, 135.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8533 (test) 0.7983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 828/828 [00:06<00:00, 135.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8631 (test) 0.8092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 828/828 [00:06<00:00, 136.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8557 (test) 0.8320\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 828/828 [00:06<00:00, 136.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8584 (test) 0.8113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 828/828 [00:06<00:00, 135.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8549 (test) 0.7968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 828/828 [00:06<00:00, 136.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8570 (test) 0.7812\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 828/828 [00:06<00:00, 136.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8566 (test) 0.8336\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 828/828 [00:06<00:00, 136.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8505 (test) 0.8173\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 828/828 [00:06<00:00, 135.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8532 (test) 0.7834\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 828/828 [00:06<00:00, 136.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8548 (test) 0.8236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 828/828 [00:06<00:00, 136.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8525 (test) 0.8133\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 828/828 [00:06<00:00, 136.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8503 (test) 0.8325\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 828/828 [00:06<00:00, 136.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8547 (test) 0.8291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 828/828 [00:06<00:00, 136.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8552 (test) 0.7803\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 828/828 [00:06<00:00, 136.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8591 (test) 0.8426\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 828/828 [00:06<00:00, 135.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8564 (test) 0.7947\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 828/828 [00:06<00:00, 136.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8525 (test) 0.8096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 828/828 [00:06<00:00, 134.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8533 (test) 0.8086\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 828/828 [00:06<00:00, 135.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8557 (test) 0.8322\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 828/828 [00:06<00:00, 134.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8612 (test) 0.7918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 828/828 [00:06<00:00, 135.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8583 (test) 0.8242\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 828/828 [00:06<00:00, 135.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8516 (test) 0.8175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 828/828 [00:06<00:00, 135.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8573 (test) 0.8182\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 828/828 [00:06<00:00, 134.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8475 (test) 0.8077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 828/828 [00:06<00:00, 135.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8586 (test) 0.8309\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 828/828 [00:06<00:00, 135.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8545 (test) 0.8299\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 828/828 [00:06<00:00, 133.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val) 0.8596 (test) 0.8217\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86:  75%|███████▌  | 625/828 [00:04<00:01, 134.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(apply_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_idx), Y_train[batch_idx])\n\u001b[0;32m---> 45\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m epoch_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grad_scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tensorboard for training\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "run_name = \"tabm_ports_not_normalized_v2\"\n",
    "tb_log_dir = f'/home/appuser/src/logs/TabM/{run_name}'\n",
    "writer = SummaryWriter(log_dir=tb_log_dir)\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "train_size = len(train_idx)\n",
    "batch_size = 256\n",
    "epoch_size = math.ceil(train_size / batch_size)\n",
    "best = {\n",
    "    'val': -math.inf,\n",
    "    'test': -math.inf,\n",
    "    'epoch': -1,\n",
    "}\n",
    "# Early stopping: the training stops when\n",
    "# there are more than `patience` consequtive bad updates.\n",
    "patience = 200\n",
    "remaining_patience = patience\n",
    "\n",
    "\n",
    "\n",
    "print('-' * 88 + '\\n')\n",
    "for epoch in range(n_epochs):\n",
    "    batches = (\n",
    "        torch.randperm(train_size, device=device).split(batch_size)\n",
    "        if model.share_training_batches\n",
    "        else [\n",
    "            x.transpose(0, 1).flatten()\n",
    "            for x in torch.rand((model.k, train_size), device=device)\n",
    "            .argsort(dim=1)\n",
    "            .split(batch_size, dim=1)\n",
    "        ]\n",
    "    )\n",
    "    epoch_loss = 0.0\n",
    "    epoch_num = 0\n",
    "    for batch_idx in tqdm(batches, desc=f'Epoch {epoch}'):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(apply_model('train', batch_idx), Y_train[batch_idx])\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_num += 1\n",
    "        if grad_scaler is None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            grad_scaler.scale(loss).backward()  # type: ignore\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "    writer.add_scalar('validation_macro_F1', val_score, epoch+1)\n",
    "    writer.add_scalar('test_macro_F1', test_score, epoch+1)\n",
    "    writer.add_scalar('train_loss', epoch_loss/epoch_num, epoch+1)\n",
    "    print(f'(val) {val_score:.4f} (test) {test_score:.4f}')\n",
    "\n",
    "    if test_score > best['test']:\n",
    "        print('🌸 New best epoch! 🌸')\n",
    "        best = {'val': val_score, 'test': test_score, 'epoch': epoch}\n",
    "        remaining_patience = patience\n",
    "        torch.save(model.state_dict(), f\"{run_name}.pth\")\n",
    "    else:\n",
    "        remaining_patience -= 1\n",
    "\n",
    "    if remaining_patience < 0:\n",
    "        break\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "print('\\n\\nResult:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "arch_type = 'tabm'\n",
    "bins = None\n",
    "\n",
    "# arch_type = 'tabm-mini'\n",
    "# bins = rtdl_num_embeddings.compute_bins(data['train']['x_cont'])\n",
    "\n",
    "model = Model(\n",
    "    n_num_features=n_cont_features,\n",
    "    cat_cardinalities=[],\n",
    "    n_classes=n_classes,\n",
    "    backbone={\n",
    "        'type': 'MLP',\n",
    "        'n_blocks': 3 if bins is None else 2,\n",
    "        'd_block': 256,\n",
    "        'dropout': 0.2,\n",
    "        'n_blocks': 5\n",
    "    },\n",
    "    bins=bins,\n",
    "    num_embeddings=(\n",
    "        None\n",
    "        if bins is None\n",
    "        else {\n",
    "            'type': 'PiecewiseLinearEmbeddings',\n",
    "            'd_embedding': 16,\n",
    "            'activation': False,\n",
    "            'version': 'B',\n",
    "        }\n",
    "    ),\n",
    "    arch_type=arch_type,\n",
    "    k=48,\n",
    "    share_training_batches=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.autocast(device.type, enabled=amp_enabled, dtype=amp_dtype)  # type: ignore[code]\n",
    "def apply_model(part: str, idx: Tensor) -> Tensor:\n",
    "    return (\n",
    "        model(\n",
    "            data[part]['x_cont'][idx],\n",
    "            data[part]['x_cat'][idx] if 'x_cat' in data[part] else None,\n",
    "        )\n",
    "        .squeeze(-1)  # Remove the last dimension for regression tasks.\n",
    "        .float()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10834/10834 [00:06<00:00, 1695.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9909\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score        support\n",
      "0              0.995859  0.995194  0.995526  125892.000000\n",
      "1              0.906769  0.930537  0.918499    3052.000000\n",
      "2              0.649669  0.652133  0.650899    1055.000000\n",
      "accuracy       0.990892  0.990892  0.990892       0.990892\n",
      "macro avg      0.850766  0.859288  0.854975  129999.000000\n",
      "weighted avg   0.990958  0.990892  0.990921  129999.000000\n",
      "\n",
      "F1 (Micro): 0.9909\n",
      "F1 (Macro): 0.8550\n",
      "\n",
      "Class-wise Accuracy (Recall):\n",
      " 0    0.995194\n",
      "1    0.930537\n",
      "2    0.652133\n",
      "Name: recall, dtype: float64\n",
      "\n",
      "Confusion Matrix:\n",
      " [[125287    270    335]\n",
      " [   176   2840     36]\n",
      " [   345     22    688]]\n"
     ]
    }
   ],
   "source": [
    "# Inference on the test dataset\n",
    "model.load_state_dict(torch.load('/home/appuser/src/visualization/tabm_no_frequ_features_extended_more_weight.pth'))\n",
    "model.eval()\n",
    "\n",
    "part = \"test\"\n",
    "\n",
    "eval_batch_size = 12\n",
    "# y_pred: np.ndarray = (\n",
    "#     torch.cat(\n",
    "#         [\n",
    "#             apply_model(part, idx).cpu()\n",
    "#             for idx in torch.arange(len(data[part]['y']), device=device).split(\n",
    "#                 eval_batch_size\n",
    "#             )\n",
    "#         ]\n",
    "#     )\n",
    "#     .numpy()\n",
    "# )\n",
    "\n",
    "y_pred_list = []\n",
    "for idx in tqdm(torch.arange(len(data[part]['y']), device=device).split(eval_batch_size)):\n",
    "    with torch.no_grad():\n",
    "        preds = apply_model(part, idx).cpu()\n",
    "        probs = scipy.special.softmax(preds.numpy(), axis=-1)\n",
    "        averaged = probs.mean(1)  # shape: [B, C]\n",
    "        preds_class = np.argmax(averaged, axis=1)\n",
    "        y_pred_list.append(preds_class)\n",
    "\n",
    "y_pred = np.concatenate(y_pred_list)\n",
    "\n",
    "y_test = data[part]['y'].cpu().numpy()\n",
    "\n",
    "# Overall accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report (includes precision, recall, F1 per class + macro/micro)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(\"\\nClassification Report:\\n\", report_df)\n",
    "\n",
    "# F1 scores\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"\\nF1 (Micro): {f1_micro:.4f}\")\n",
    "print(f\"F1 (Macro): {f1_macro:.4f}\")\n",
    "\n",
    "# Class-wise accuracy (same as recall per class)\n",
    "class_wise_accuracy = report_df.loc[[str(i) for i in np.unique(y_test)], \"recall\"]\n",
    "print(\"\\nClass-wise Accuracy (Recall):\\n\", class_wise_accuracy)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
