{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabM\n",
    "\n",
    "This is a standalone usage example for the TabM project.\n",
    "The easiest way to run it is [Pixi](https://pixi.sh/latest/#installation):\n",
    "\n",
    "```shell\n",
    "git clone https://github.com/yandex-research/tabm\n",
    "cd tabm\n",
    "\n",
    "# With GPU:\n",
    "pixi run -e cuda jupyter-lab example.ipynb\n",
    "\n",
    "# Without GPU:\n",
    "pixi run jupyter-lab example.ipynb\n",
    "```\n",
    "\n",
    "For the full overview of the project, and for non-Pixi environment setups, see README in the repository:\n",
    "https://github.com/yandex-research/tabm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E402\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from typing import Literal, NamedTuple\n",
    "import sklearn\n",
    "import scipy\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch import Tensor\n",
    "from tqdm.std import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from collections import Counter\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "from tabm_reference import Model, make_parameter_groups\n",
    "\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed + 1)\n",
    "torch.manual_seed(seed + 2)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_TO_NUM_LABELS = {\n",
    "    \"Normal traffic\": 0,\n",
    "    \"Suspicious traffic\": 1,\n",
    "    \"DDoS attack\": 2,\n",
    "}\n",
    "\n",
    "component_columns = [\n",
    "    \"Attack ID\", \"Detect count\", \"Card\", \"Victim IP\", \"Port number\",\n",
    "    \"Attack code\", \"Significant flag\", \"Packet speed\", \"Data speed\", \"Avg packet len\",\n",
    "    \"Source IP count\", \"Time\"\n",
    "]\n",
    "\n",
    "event_columns = [\n",
    "    \"Attack ID\", \"Card\", \"Victim IP\", \"Port number\", \"Attack code\", \n",
    "    \"Detect count\", \"Significant flag\", \"Packet speed\", \"Data speed\", \n",
    "    \"Avg packet len\", \"Avg source IP count\", \"Start time\", \"End time\", \n",
    "    \"Whitelist flag\", \"Type\"\n",
    "]\n",
    "\n",
    "attack_code_ports = {\n",
    "    \"ACK Attack\": [],\n",
    "    \"CHARGEN\": [19],\n",
    "    \"CLDAP\": [389],\n",
    "    \"CoAP\": [5683],\n",
    "    \"DNS\": [53],\n",
    "    \"Generic UDP\": [],\n",
    "    \"IPV4 fragmentation\": [],\n",
    "    \"RDP\": [3389],\n",
    "    \"RPC\": [111, 135],\n",
    "    \"SNMP\": [161, 162],\n",
    "    \"SYN Attack\": [],\n",
    "    \"TCP Anomaly\": [],\n",
    "    \"NTP\": [123],\n",
    "    \"SSDP\": [1900],\n",
    "    \"Sentinel\": [],\n",
    "    \"Memcached\": [11211],\n",
    "    \"RIP\": [520],\n",
    "    \"TFTP\": [69],\n",
    "    \"WSD\": [3702],\n",
    "}\n",
    "\n",
    "# Port to attack mapping for fast lookup\n",
    "port_to_attack = {}\n",
    "for attack, ports in attack_code_ports.items():\n",
    "    for port in ports:\n",
    "        port_to_attack.setdefault(port, []).append(attack)\n",
    "\n",
    "class DDoSDataset(Dataset):\n",
    "    def __init__(self, split, use_inferred_atck_code):\n",
    "        self.train_data_paths = [f'/home/appuser/data/train/SCLDDoS2024_SetA_events_extended.csv',\n",
    "                                 f'/home/appuser/data/train/SCLDDoS2024_SetB_events_extended.csv']\n",
    "        self.test_data_paths = [f'/home/appuser/data/test/SCLDDoS2024_SetC_events_extended.csv']     \n",
    "        \n",
    "        self.inferred_train_data_paths = [f'/home/appuser/data/train/A_B_inferred_attack_code.csv']\n",
    "        self.inferred_test_data_paths = [f'/home/appuser/data/test/C_inferred_attack_code.csv']\n",
    "        \n",
    "        self.gen_data_paths = [f'/home/appuser/data/gen/SCLDDoS2024_SetD_events_extended.csv']\n",
    "        \n",
    "        self.inferred_gen_data_paths = [f'/home/appuser/data/gen/D_inferred_attack_code.csv']\n",
    "        \n",
    "        self.split = split   \n",
    "        self.use_inferred_atck_code = use_inferred_atck_code\n",
    "        \n",
    "        if split == 'train':\n",
    "            if use_inferred_atck_code:\n",
    "                self.features, self.lables = self.load_data(self.inferred_train_data_paths, apply_smote=False)\n",
    "            else:\n",
    "                self.features, self.lables = self.load_data(self.train_data_paths, apply_smote=False)            \n",
    "        elif split == 'test':\n",
    "            if use_inferred_atck_code:\n",
    "                self.features, self.lables = self.load_data(self.inferred_test_data_paths, apply_smote=False)\n",
    "            else:\n",
    "                self.features, self.lables = self.load_data(self.test_data_paths, apply_smote=False)\n",
    "        elif split == 'gen':\n",
    "            if use_inferred_atck_code:\n",
    "                self.features, self.lables = self.load_data(self.inferred_gen_data_paths, apply_smote=False)\n",
    "            else:\n",
    "                self.features, self.lables = self.load_data(self.gen_data_paths, apply_smote=False)\n",
    "        else:\n",
    "            print(\"Invalid split. Use 'train' or 'test'\")\n",
    "            \n",
    "    \n",
    "    def get_ports(self):\n",
    "        return self.ddos_ports\n",
    "    \n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.features.numpy(), self.lables.numpy()\n",
    "        \n",
    "    # preload the data as it makes the training much faster (and it easily fits in memory)\n",
    "    def load_data(self, data_paths, apply_smote=False, undersample=False, sample_factor=4):\n",
    "        data = []\n",
    "        \n",
    "        for path in data_paths:\n",
    "            event_df = pd.read_csv(path).fillna(0)\n",
    "            data.append(event_df)\n",
    "\n",
    "            # Attempt to load corresponding component file\n",
    "            comp_path = path.replace('_events_extended.csv', '_components.csv')\n",
    "            ref_event_path = path.replace('_events_extended.csv', '_events.csv')\n",
    "        \n",
    "        df = pd.concat(data, ignore_index=True)\n",
    "            \n",
    "        \n",
    "        self.ddos_ports = df[df['Type'] == \"DDoS attack\"][\"Port number\"].unique()\n",
    "        \n",
    "        #feature_columns = df.columns[:19]  # All except the last column\n",
    "        \n",
    "        # comment this line I u need the frequency features\n",
    "        df = df.loc[:, ~df.columns.str.contains('Ac')]\n",
    "        feature_columns = df.columns[:-1]\n",
    "        label_column = df.columns[-1]  # The last column\n",
    "        \n",
    "        # Convert categorical labels to numeric using the dictionary\n",
    "        df[label_column] = df[label_column].map(CAT_TO_NUM_LABELS)\n",
    "        \n",
    "        # Check for missing or unknown labels\n",
    "        if df[label_column].isna().any():\n",
    "            print(df[label_column].isna().sum(), \"missing labels\")\n",
    "\n",
    "        X = df[feature_columns]\n",
    "        y = df[label_column]\n",
    "        \n",
    "        # one-hot encode the categorical features\n",
    "        if self.use_inferred_atck_code:\n",
    "            split_labels = X['Inferred Attack Code'].str.split('; ')\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            attack_code_ohe = pd.DataFrame(mlb.fit_transform(split_labels),\n",
    "                                        columns=[f\"Inferred Attack Code_{cls}\" for cls in mlb.classes_],\n",
    "                                        index=X.index)\n",
    "\n",
    "            # Drop the original column and join the new one-hot encoded columns\n",
    "            X = X.drop(columns=['Inferred Attack Code'])\n",
    "            X = X.join(attack_code_ohe)\n",
    "            \n",
    "            \n",
    "            #X = pd.get_dummies(X, columns=[\"Inferred Attack Code\"], drop_first=False)        \n",
    "        \n",
    "        self.columns = X.columns\n",
    "        \n",
    "        cols = list(X.columns)\n",
    "        \n",
    "        \n",
    "        # Normalize the features\n",
    "        #features = self.normalize(features)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        if apply_smote and self.split == 'train':\n",
    "            class_counts = Counter(y)\n",
    "            sm = SMOTE(sampling_strategy={0: class_counts[0], 1:50000, 2:50000}, random_state=42)\n",
    "            sm = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "            sm = BorderlineSMOTE(sampling_strategy='not majority', random_state=42)\n",
    "            X_resampled, y_resampled = sm.fit_resample(X.values, y.values)\n",
    "            features = torch.tensor(X_resampled, dtype=torch.float32)\n",
    "            labels = torch.tensor(y_resampled, dtype=torch.long)\n",
    "        else:\n",
    "            features = torch.tensor(X.values, dtype=torch.float32)\n",
    "            labels = torch.tensor(y.values, dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if undersample and self.split == 'train':\n",
    "            # Undersample the majority class (label=0)\n",
    "            class_0_indices = np.where(labels.cpu().numpy() == 0)[0]\n",
    "            class_1_indices = np.where(labels.cpu().numpy() == 1)[0]\n",
    "            class_2_indices = np.where(labels.cpu().numpy() == 2)[0]\n",
    "\n",
    "            # Randomly undersample the majority class\n",
    "            num_class_0_samples = sample_factor*(len(class_1_indices) + len(class_2_indices))  # Same number as the minority class\n",
    "            class_0_indices_undersampled = np.random.choice(class_0_indices, num_class_0_samples, replace=False)\n",
    "\n",
    "            # Concatenate indices of class 1, 2, and undersampled class 0\n",
    "            undersampled_indices = np.concatenate([class_0_indices_undersampled, class_1_indices, class_2_indices])\n",
    "\n",
    "            # Subset the dataset to include only the sampled indices\n",
    "            features = features[undersampled_indices]\n",
    "            labels = labels[undersampled_indices]\n",
    "\n",
    "        return features, labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        y = self.lables[idx]\n",
    "\n",
    "        return x, y  # y is class index (long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble the datatset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train and validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskType = Literal['regression', 'binclass', 'multiclass']\n",
    "\n",
    "# Classification.\n",
    "n_classes = 3\n",
    "assert n_classes >= 2\n",
    "task_type: TaskType = 'binclass' if n_classes == 2 else 'multiclass'\n",
    "\n",
    "dataset = DDoSDataset(split='train', use_inferred_atck_code=False)\n",
    "X_cont = dataset.features.numpy()\n",
    "Y = dataset.lables.numpy()\n",
    "\n",
    "# >>> Continuous features.\n",
    "X_cont: np.ndarray = X_cont.astype(np.float32)\n",
    "n_cont_features = X_cont.shape[1]\n",
    "\n",
    "# >>> Labels.\n",
    "if task_type == 'regression':\n",
    "    Y = Y.astype(np.float32)\n",
    "else:\n",
    "    assert n_classes is not None\n",
    "    Y = Y.astype(np.int64)\n",
    "    assert set(Y.tolist()) == set(\n",
    "        range(n_classes)\n",
    "    ), 'Classification labels must form the range [0, 1, ..., n_classes - 1]'\n",
    "\n",
    "# >>> Split the dataset.\n",
    "all_idx = np.arange(len(Y))\n",
    "train_idx, val_idx = sklearn.model_selection.train_test_split(\n",
    "    all_idx, train_size=0.8\n",
    ")\n",
    "\n",
    "data_numpy = {\n",
    "    'train': {'x_cont': X_cont[train_idx], 'y': Y[train_idx]},\n",
    "    'val': {'x_cont': X_cont[val_idx], 'y': Y[val_idx]},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Dataset C as the testing class\n",
    "\n",
    "n_classes = 3\n",
    "assert n_classes >= 2\n",
    "task_type: TaskType = 'binclass' if n_classes == 2 else 'multiclass'\n",
    "\n",
    "dataset = DDoSDataset(split='test', use_inferred_atck_code=False)\n",
    "X_cont = dataset.features.numpy()\n",
    "Y = dataset.lables.numpy()\n",
    "\n",
    "# >>> Continuous features.\n",
    "X_cont: np.ndarray = X_cont.astype(np.float32)\n",
    "n_cont_features = X_cont.shape[1]\n",
    "\n",
    "# >>> Labels.\n",
    "if task_type == 'regression':\n",
    "    Y = Y.astype(np.float32)\n",
    "else:\n",
    "    assert n_classes is not None\n",
    "    Y = Y.astype(np.int64)\n",
    "    assert set(Y.tolist()) == set(\n",
    "        range(n_classes)\n",
    "    ), 'Classification labels must form the range [0, 1, ..., n_classes - 1]'\n",
    "    \n",
    "    \n",
    "data_numpy['test'] = {'x_cont': X_cont, 'y': Y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generalization split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "assert n_classes >= 2\n",
    "task_type: TaskType = 'binclass' if n_classes == 2 else 'multiclass'\n",
    "\n",
    "dataset = DDoSDataset(split='gen', use_inferred_atck_code=False)\n",
    "X_cont = dataset.features.numpy()\n",
    "Y = dataset.lables.numpy()\n",
    "\n",
    "# >>> Continuous features.\n",
    "X_cont: np.ndarray = X_cont.astype(np.float32)\n",
    "n_cont_features = X_cont.shape[1]\n",
    "\n",
    "# >>> Labels.\n",
    "if task_type == 'regression':\n",
    "    Y = Y.astype(np.float32)\n",
    "else:\n",
    "    assert n_classes is not None\n",
    "    Y = Y.astype(np.int64)\n",
    "    assert set(Y.tolist()) == set(\n",
    "        range(n_classes)\n",
    "    ), 'Classification labels must form the range [0, 1, ..., n_classes - 1]'\n",
    "    \n",
    "    \n",
    "data_numpy['gen'] = {'x_cont': X_cont, 'y': Y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the QuantileTransformer on the training set.\n",
    "X_cont_train_numpy = data_numpy['train']['x_cont']\n",
    "noise = (\n",
    "    np.random.default_rng(0)\n",
    "    .normal(0.0, 1e-5, X_cont_train_numpy.shape)\n",
    "    .astype(X_cont_train_numpy.dtype)\n",
    ")\n",
    "preprocessing = sklearn.preprocessing.QuantileTransformer(\n",
    "    n_quantiles=max(min(len(train_idx) // 30, 1000), 10),\n",
    "    output_distribution='normal',\n",
    "    subsample=10**9,\n",
    ").fit(X_cont_train_numpy + noise)\n",
    "del X_cont_train_numpy\n",
    "\n",
    "\n",
    "# Apply the preprocessing to the training, test and validation sets.\n",
    "for part in data_numpy:\n",
    "    # Transform only continuous features\n",
    "    data_numpy[part]['x_cont'] = preprocessing.transform(\n",
    "        data_numpy[part]['x_cont']\n",
    "    )\n",
    "\n",
    "    \n",
    "regression_label_stats = None\n",
    "Y_train = data_numpy['train']['y'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PyTorch settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:        CUDA\n",
      "AMP:           False (dtype: torch.bfloat16)\n",
      "torch.compile: False\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convert data to tensors\n",
    "data = {\n",
    "    part: {k: torch.as_tensor(v, device=device) for k, v in data_numpy[part].items()}\n",
    "    for part in data_numpy\n",
    "}\n",
    "Y_train = torch.as_tensor(Y_train, device=device)\n",
    "if task_type == 'regression':\n",
    "    for part in data:\n",
    "        data[part]['y'] = data[part]['y'].float()\n",
    "    Y_train = Y_train.float()\n",
    "\n",
    "# Automatic mixed precision (AMP)\n",
    "# torch.float16 is implemented for completeness,\n",
    "# but it was not tested in the project,\n",
    "# so torch.bfloat16 is used by default.\n",
    "amp_dtype = (\n",
    "    torch.bfloat16\n",
    "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "    else torch.float16\n",
    "    if torch.cuda.is_available()\n",
    "    else None\n",
    ")\n",
    "# Changing False to True will result in faster training on compatible hardware.\n",
    "amp_enabled = False and amp_dtype is not None\n",
    "grad_scaler = torch.cuda.amp.GradScaler() if amp_dtype is torch.float16 else None  # type: ignore\n",
    "\n",
    "# torch.compile\n",
    "compile_model = False\n",
    "\n",
    "# fmt: off\n",
    "print(\n",
    "    f'Device:        {device.type.upper()}'\n",
    "    f'\\nAMP:           {amp_enabled} (dtype: {amp_dtype})'\n",
    "    f'\\ntorch.compile: {compile_model}'\n",
    ")\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "arch_type = 'tabm' # 'tabm' or 'tabm-mini' or 'tabm-packed'\n",
    "bins = None\n",
    "\n",
    "model = Model(\n",
    "    n_num_features=data['train']['x_cont'].shape[1],\n",
    "    cat_cardinalities=[],\n",
    "    n_classes=n_classes,\n",
    "    backbone={\n",
    "        'type': 'MLP',\n",
    "        'n_blocks': 3 if bins is None else 2,\n",
    "        'd_block': 256,\n",
    "        'dropout': 0.2,\n",
    "        'n_blocks': 5\n",
    "    },\n",
    "    bins=bins,\n",
    "    num_embeddings=(\n",
    "        None\n",
    "        if bins is None\n",
    "        else {\n",
    "            'type': 'PiecewiseLinearEmbeddings',\n",
    "            'd_embedding': 16,\n",
    "            'activation': False,\n",
    "            'version': 'B',\n",
    "        }\n",
    "    ),\n",
    "    arch_type=arch_type,\n",
    "    k=48,\n",
    "    share_training_batches=True,\n",
    ").to(device)\n",
    "optimizer = torch.optim.AdamW(make_parameter_groups(model), lr=1e-3, weight_decay=3e-4)\n",
    "\n",
    "if compile_model:\n",
    "    # NOTE\n",
    "    # `torch.compile` is intentionally called without the `mode` argument\n",
    "    # (mode=\"reduce-overhead\" caused issues during training with torch==2.0.1).\n",
    "    model = torch.compile(model)\n",
    "    evaluation_mode = torch.no_grad\n",
    "else:\n",
    "    evaluation_mode = torch.inference_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evalutation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score before training: 0.3311\n"
     ]
    }
   ],
   "source": [
    "@torch.autocast(device.type, enabled=amp_enabled, dtype=amp_dtype)  # type: ignore[code]\n",
    "def apply_model(part: str, idx: Tensor) -> Tensor:\n",
    "    return (\n",
    "        model(\n",
    "            data[part]['x_cont'][idx],\n",
    "            data[part]['x_cat'][idx] if 'x_cat' in data[part] else None,\n",
    "        )\n",
    "        .squeeze(-1)  # Remove the last dimension for regression tasks.\n",
    "        .float()\n",
    "    )\n",
    "\n",
    "\n",
    "base_loss_fn = F.mse_loss if task_type == 'regression' else F.cross_entropy\n",
    "#weight = torch.tensor([1.0, 1.0, 1.0], device=device)\n",
    "\n",
    "\n",
    "def loss_fn(y_pred: Tensor, y_true: Tensor, weight: float = None) -> Tensor:\n",
    "    # TabM produces k predictions. Each of them must be trained separately.\n",
    "    # (regression)     y_pred.shape == (batch_size, k)\n",
    "    # (classification) y_pred.shape == (batch_size, k, n_classes)\n",
    "    k = y_pred.shape[-1 if task_type == 'regression' else -2]\n",
    "    return base_loss_fn(\n",
    "        y_pred.flatten(0, 1),\n",
    "        y_true.repeat_interleave(k) if model.share_training_batches else y_true,\n",
    "        weight=weight,\n",
    "    )\n",
    "\n",
    "\n",
    "@evaluation_mode()\n",
    "def evaluate(part: str) -> float:\n",
    "    model.eval()\n",
    "\n",
    "    # When using torch.compile, you may need to reduce the evaluation batch size.\n",
    "    eval_batch_size = 8096\n",
    "    y_pred: np.ndarray = (\n",
    "        torch.cat(\n",
    "            [\n",
    "                apply_model(part, idx)\n",
    "                for idx in torch.arange(len(data[part]['y']), device=device).split(\n",
    "                    eval_batch_size\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    if task_type == 'regression':\n",
    "        # Transform the predictions back to the original label space.\n",
    "        assert regression_label_stats is not None\n",
    "        y_pred = y_pred * regression_label_stats.std + regression_label_stats.mean\n",
    "\n",
    "    # Compute the mean of the k predictions.\n",
    "    if task_type != 'regression':\n",
    "        # For classification, the mean must be computed in the probabily space.\n",
    "        y_pred = scipy.special.softmax(y_pred, axis=-1)\n",
    "    y_pred = y_pred.mean(1)\n",
    "\n",
    "    y_true = data[part]['y'].cpu().numpy()\n",
    "    score = (\n",
    "        -(sklearn.metrics.mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "        if task_type == 'regression'\n",
    "        else sklearn.metrics.f1_score(y_true, y_pred.argmax(1), average='macro')\n",
    "    )\n",
    "    return float(score)  # The higher -- the better.\n",
    "\n",
    "\n",
    "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard for training\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "run_name = \"weights/TabM_no_frequ_features_extended_more_weight\"\n",
    "tb_log_dir = f'/home/appuser/src/logs/TabM/{run_name}'\n",
    "writer = SummaryWriter(log_dir=tb_log_dir)\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_weight = torch.tensor([1.0, 1.0, 3.141592], device=device)\n",
    "\n",
    "train_size = len(train_idx)\n",
    "batch_size = 256\n",
    "epoch_size = math.ceil(train_size / batch_size)\n",
    "best = {\n",
    "    'val': -math.inf,\n",
    "    'test': -math.inf,\n",
    "    'epoch': -1,\n",
    "}\n",
    "\n",
    "# Early stopping: the training stops when\n",
    "# there are more than `patience` consequtive bad updates.\n",
    "patience = 1000\n",
    "remaining_patience = patience\n",
    "\n",
    "print('-' * 88 + '\\n')\n",
    "for epoch in range(n_epochs):\n",
    "    batches = (\n",
    "        torch.randperm(train_size, device=device).split(batch_size)\n",
    "        if model.share_training_batches\n",
    "        else [\n",
    "            x.transpose(0, 1).flatten()\n",
    "            for x in torch.rand((model.k, train_size), device=device)\n",
    "            .argsort(dim=1)\n",
    "            .split(batch_size, dim=1)\n",
    "        ]\n",
    "    )\n",
    "    epoch_loss = 0.0\n",
    "    epoch_num = 0\n",
    "    for batch_idx in tqdm(batches, desc=f'Epoch {epoch}'):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(apply_model('train', batch_idx), Y_train[batch_idx], weight=loss_weight)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_num += 1\n",
    "        if grad_scaler is None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            grad_scaler.scale(loss).backward()  # type: ignore\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "    writer.add_scalar('validation_macro_F1', val_score, epoch+1)\n",
    "    writer.add_scalar('test_macro_F1', test_score, epoch+1)\n",
    "    writer.add_scalar('train_loss', epoch_loss/epoch_num, epoch+1)\n",
    "    print(f'(val) {val_score:.4f} (test) {test_score:.4f}')\n",
    "\n",
    "    if test_score > best['test']:\n",
    "        print('🌸 New best epoch! 🌸')\n",
    "        best = {'val': val_score, 'test': test_score, 'epoch': epoch}\n",
    "        remaining_patience = patience\n",
    "        torch.save(model.state_dict(), f\"{run_name}.pth\")\n",
    "    else:\n",
    "        remaining_patience -= 1\n",
    "\n",
    "    if remaining_patience < 0:\n",
    "        break\n",
    "\n",
    "    print()\n",
    "    if (epoch+1) % 30 == 0:\n",
    "        loss_weight += torch.tensor([0.0, 0.0, 0.0], device=device)\n",
    "\n",
    "\n",
    "print('\\n\\nResult:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference  \n",
    "! If you only want to run inference, make sure to run all of the blocks above (except for the training) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 476960\n",
      "------------------------------------------------------------------------------\n",
      "Evaluating test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1621/10834 [00:01<00:06, 1359.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m preds \u001b[38;5;241m=\u001b[39m apply_model(part, idx)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     29\u001b[0m probs \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mspecial\u001b[38;5;241m.\u001b[39msoftmax(preds\u001b[38;5;241m.\u001b[39mnumpy(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m averaged \u001b[38;5;241m=\u001b[39m \u001b[43mprobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: [B, C]\u001b[39;00m\n\u001b[1;32m     31\u001b[0m preds_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(averaged, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m y_pred_list\u001b[38;5;241m.\u001b[39mappend(preds_class)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:118\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    115\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "run_name = \"weights/TabM_no_frequ_features_extended_more_weight\"\n",
    "\n",
    "model.load_state_dict(torch.load(f\"{run_name}.pth\"))\n",
    "model.eval()\n",
    "\n",
    "splits = [\"test\", \"gen\"]\n",
    "\n",
    "eval_batch_size = 12\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {num_params}\")\n",
    "\n",
    "for part in splits:\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print(f\"Evaluating {part} set...\")\n",
    "    y_pred_list = []\n",
    "    for idx in tqdm(torch.arange(len(data[part]['y']), device=device).split(eval_batch_size)):\n",
    "        with torch.no_grad():\n",
    "            preds = apply_model(part, idx).cpu()\n",
    "            probs = scipy.special.softmax(preds.numpy(), axis=-1)\n",
    "            averaged = probs.mean(1)  # shape: [B, C]\n",
    "            preds_class = np.argmax(averaged, axis=1)\n",
    "            y_pred_list.append(preds_class)\n",
    "\n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "\n",
    "    y_test = data[part]['y'].cpu().numpy()\n",
    "\n",
    "    # Overall accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Classification report (includes precision, recall, F1 per class + macro/micro)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    print(\"\\nClassification Report:\\n\", report_df)\n",
    "\n",
    "    # F1 scores\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"\\nF1 (Micro): {f1_micro:.4f}\")\n",
    "    print(f\"F1 (Macro): {f1_macro:.4f}\")\n",
    "\n",
    "    # Class-wise accuracy (same as recall per class)\n",
    "    class_wise_accuracy = report_df.loc[[str(i) for i in np.unique(y_test)], \"recall\"]\n",
    "    print(\"\\nClass-wise Accuracy (Recall):\\n\", class_wise_accuracy)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Reorder the confusion matrix so it matches the order of the labels for the other models\n",
    "    new_order = [2, 0, 1]\n",
    "    reordered_conf_matrix = conf_matrix[np.ix_(new_order, new_order)]\n",
    "\n",
    "    # Corresponding class labels\n",
    "    labels = [\"DDoS attack\", \"Normal traffic\", \"Suspicious traffic\"]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=reordered_conf_matrix, display_labels=labels)\n",
    "    disp.plot(cmap='Blues', values_format=\"d\")\n",
    "    plt.imshow(np.log1p(reordered_conf_matrix), cmap='Blues')  # Log transform for better visualization\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
